# -*- coding: utf-8 -*-
"""mid_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CvfPmdelmpY_eeMhN7hAt2o2GXLLhz36
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
#판다스로 바로 정리한다.

raw_dataset = pd.read_csv('/content/sample_data/insurance.csv',
                          na_values='?', sep=',', skipinitialspace=True, header=0)
dataset = raw_dataset.copy()
print(dataset)
print(dataset.shape)

dataset = dataset.dropna()

#개인적인 생각이지만, yes, no와 남녀 구분은 딱히 원핫을 할 필요 없다.
#yes라서 보험료가 올라가는 거면, 굳이 원 핫 엔코딩을 하는건 연산량을 늘릴 뿐이다.
#그러므로 원 핫 엔코딩을 하기 보단, yes, no를 1과 0으로 바꾸는게 좋다고 생각한다.
#추가->하루 정도 생각해보고 나서 깨달은 사실-> 1과 0으로 바꾸면 0인건 다음 레이어에 0을 반환하므로 안된다.
#그러므로 0대신 1,10같이 극단적인 수를 넣어서 해결하자.
dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')
dataset.tail()

#사족이지만, 우린 데이터의 소규모와 대규모를 비교하기 위해 전체데이터 80%셋과 20%셋을 둘다 해볼 생각입니다.
train_dataset = dataset.sample(frac=0.8, random_state=0)
test_dataset = dataset.drop(train_dataset.index)
train_features = train_dataset.copy()
test_features = test_dataset.copy()

train_labels = train_features.pop('charges')
test_labels = test_features.pop('charges')

print(train_labels)
print(test_labels)

import tensorflow as tf

from tensorflow import train
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
import matplotlib.pyplot as plt
import numpy as np

normalizer=preprocessing.Normalization()
normalizer.adapt(np.array(train_features))
print(normalizer.mean.numpy())

def build_and_compile_model(norm):
  model = keras.Sequential([
      norm,
      layers.Dense(81, activation='relu'),
      layers.Dense(81, activation='relu'),
      layers.Dense(1)
  ])

  model.compile(loss='mean_absolute_error',
               optimizer=tf.keras.optimizers.Adam(0.001))
  return model

dnn_model = build_and_compile_model(normalizer)
dnn_model2 = build_and_compile_model(normalizer)
dnn_model.summary()

# Commented out IPython magic to ensure Python compatibility.
# 
# #이건 비교를 위해 소규모 데이터(편의상 테스트셋을 이용)으로, 자료량의 중요성을 분석하기 위해 존재한다.
# %%time
# test_results = dnn_model2.fit(
#     test_features, test_labels,
#     validation_split=0.2,
#     verbose=0, epochs=1000)

# Commented out IPython magic to ensure Python compatibility.
# #트레인 셋으로 분석한 결과
# %%time
# history = dnn_model.fit(
#     train_features, train_labels,
#     validation_split=0.2,
#     verbose=0, epochs=100)

def plot_loss(history):
  plt.plot(history.history['loss'], label='loss')
  plt.plot(history.history['val_loss'], label='val_loss')
  #plt.ylim([0.0014,0.0018])
  plt.xlabel('Epoch')
  plt.ylabel('Error [MPG]')
  plt.legend()
  plt.grid(True)

#분산과 에러가 1:1을 이루면, 정규분포에 가까운 형태의 예상 모델이 되겠다.
#추가로 개인적으로 교과서를 뒤져본 결과, 1.98의 분산의 오차범위 내로 들어가야 90%가 넘는 알고리즘이라고 한다.
plt.subplot(2,1,1)
plt.title("Big group")
plot_loss(history)

#테스트의 에포치를 늘려도, 데이터 수가 적으면, 분산이 커져서 정확도가 떨어지구나!
plt.subplot(2,1,2)
plt.title("Small group")
plot_loss(test_results)

#결론-> 자료가 많아야 정규분포에 가까워지고, 에포치는 아무리 넓혀도 의미없다->개인적인 분석: 에포치는 이미 있는데이터에서 랜덤하게 고를 뿐이니까.
#결론2-> 집단이 큰건 에포치가 작아도 괜찮지만, 집단이 작으면, 에포치가 작으면 안된다.->100번 에포치와 1000번 에포치의 차이

test_predictions = dnn_model.predict(test_features).flatten()
a = plt.axes(aspect='equal')
plt.title('Predict')
plt.scatter(test_labels, test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
lims = [0, 60000]
plt.plot(lims, lims)
#y=x에 가까워지고 있지만 뭔가 이상하다. 특정

error = test_predictions - test_labels
plt.hist(error, bins=25)
plt.xlabel('Prediction Error [MPG]')
_ = plt.ylabel('Count')

#기준값(에러:0)인 값을 중심으로 분산이 작은 종모양이 된다-> 정확도는 나쁘지 않지만, 에러차이가 -25000인것이 있으므로
#보험료를 산출하는 다른 요건이 존재함을 알 수 있다.
#분석결과->가장 중요한 수치가 바져서 특정 에러가 커진거다->최근 병에 걸린 기록(횟수) 데이터가 추가로 필요할것 같다.

print("val_loss: ",history.history['val_loss'][-1],"  loss: ",history.history['loss'][-1])
test_results = dnn_model.evaluate(test_features, test_labels, verbose=0)
print(test_results)

#어째선지 모르겠지만 엄청 차이가 벌어졌다. 원인을 분석해보고 싶지만. 며칠간 고민한 끝에, 내가 모를 무언가가 원인인것을 발견했다.
print("val_loss: ",history.history['val_loss'][-1],"  loss: ",history.history['loss'][-1])
test_results = dnn_model.evaluate(test_features, test_labels, verbose=0)
print(test_results)